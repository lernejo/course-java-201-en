include::chapter-base.adoc[]
== Tools recap

=== Git

Git is a decentralized SCM (**S**ource **C**ode **M**anagement tool).

Decentralized means that they exists multiple remotes instances of the same repository on different servers.
Typically, in the open-source community, when someone external to a project wants to contribute, this person starts by creating a copy of the repository (fork), work on this instance, then offer a submission (pull or merge request) to the project's owners.

Git is broadly used today, and succeed to other SCM tools (CVS, SVN, Mercurial, etc.).
These various tools offer the same ability to historize differentials, to allow to restore a previous version, or work on a new version in parallel, which will be later on merged on the main branch.

image::git_sample.png[align=center]

Here is the vocabulary in use:

* *commit* : a revision / version containing code modifications
* *branch* : un thread of commits
* *tag* : alias for a specific commit, ofter used to mark an _applicative version_ (1.0.25 for example)
* *merge* : merge of one branch onto another
* *checkout* : retrieve locally the code from a remote server in a specific version

==== Some useful commands

* Initialize a repository
** `git clone <url>` : copy locally a remote repository
** Ou `git init` : turn the current directory into a local repository. A default remote repository can later be attached using `git remote add origin <url>`.

* Update
** `git fetch --all --prune` : retrieve the Git database latest version
** `git pull` : on the current branch, retrieve the remote changes (merge or rebase, depending on the configuration)
** `git rebase origin/<current-branch>` : on the current branch, move local commits after those having been pushed on the remote repository

* Switch branches
** `git checkout <branch>` : set the working directory files in the latest version of `<branch>`
** `git branch -b <branch>` : create a new branch named `<branch>` with the starting point being the latest commit

* Display changes
** `git status` : display indexed (green) and not-indexed (red) local changes along with commit differences with the default remote
** `git log --oneline -n 15` : display the last 15 commits of the current branch (including their hashes)
** `git diff --stat` : display a summary of local changes
** `git diff --word-diff=color <file>` : display the the local changes of the file `<file>`

* Introduce changes
** `git add <file>` : add the file `<file>` to Git index
** `git add .` : add all (recursively) changed files to Git index
** `git reset <file>` : remove file `<file>` from Git index
** `git commit -m "<title>"` : create a new commit with all indexed changes with the title `<title>`
** `git commit --amend --no-edit` : include all indexed changes in the latest commit
** `git commit --fixup <hash>` : create a new commit with all indexed changes, "tagged" as _fix_, targeting an existing commit of ID `<hash>`
** `git rebase -i --autosquash <hash>` : start an interactive rebase until the commit of ID `<hash>` excluded, and moves _fixup_ commits right after targetted commits, and mark them for merge (fixup)

Source : https://git-scm.com/docs

==== Windows users
Git is aware of files execution bit (`chmod +x`).
As *Windows* does not handle file permission Unix does, it is recommended to disable this awareness with `git config core.fileMode false`.
To explicitly set a file as executable from Git perspective: `git update-index --chmod=+x <file>`

=== Git concepts

*Remotes* are git repositories located in remote servers.
The default remote is called *origin*.
When a local repository has been cloned (hence, not initialized), *origin* targets the URL used at the time of the clone operation.

Git stores its data in a specific directory (*.git*), which contains the graph of all revisions of all branches, local and remote.
Remote branches are available through their local name: *<remote_name>/<branch_name>*.
For example, *origin/main* is the branch *main* as seen by the *origin* server when the last synchronisation (`git fetch`) was done.
It is quite usual to have one (and one only) local version of a branch, and one more remote branches with different versions.
It is only when a push will be done to a specific remote that these versions will match.
Deleting the *.git* directory will permanently erase all revisions that have not been pushed to a remote.

The *working copy* is all the files in the local repository (expect for the *.git* directory).
Modification, creation or deletion of these files can be done without alter revisions known to Git.
In any case, Git can restore the previous state of the working copy as long as this state is recorded as a commit.

In order to _commit_ modifications of the *working copy*, they must be indexed.
The *index* allows to select only some files (and not others) when creating a commit.
Files can be added, with the `add` command, or removed, with the `reset` command.
The `status` command displays in different colors current changes, in green the indexed files, in red, the others.
Performing a commit will consider all files displayed in green.

==== Rebase
The rebase is one of the feature that place Git way ahead of its predecessors.

It allows to update a branch with its remote state without complicated merge manual actions, as long as there no conflict requiring human oversight.

[source,bash]
----
git fetch --all --prune # <1>
git log --one-line -n 10 # <2>
git rebase origin/main # <3>
----
<1> Get the latest version of all branches of the default remote (*origin*)
<2> Display the last 10 commits of the current branch
<3> Modify the history of the current branch by moving commits done after the base after the last ones pushed on the `main` branch of the remote *origin*

image::git_rebase.png[align=center]

The *rebase* command can also be used interactively to alter the local history of the current branch:

* Add changes in an exiting commit
* Change the name or description of a commit
* Merge several commits into one
* Delete commits (discarding changes)
* Change commits order

TIP: Do not use rebase on a branch shared by more than one person. Especially the `main` branch.

=== Maven

Maven is a build automation tool, for JVM-based projects.

It handles, among other functionalities:

* Dependency management
* Source code compilation
* Tests execution
* Documentation generation
* Packaging of binaries

It's plugin-based system allows to adapt to various languages (Java, Scala, Kotlin, etc.) as well as different contexts (Continuous Integration, code generation, deployment, etc.).

==== Project structure

A Maven project is organized by convention (over configuration) to avoid re-define standard parts, such as: source code, tests, etc.

A the root of a Maven project, we found:

* A pom.xml file which contains all information needed for Maven to build the project. Its minimal content is as follow:

.File pom.xml
[source,xml]
----
<?xml version="1.0"?>
<project xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"
         xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">
    <modelVersion>4.0.0</modelVersion>

    <groupId>com.mycompany</groupId> <!--1-->
    <artifactId>my-app</artifactId>
    <version>1.0.0-SNAPSHOT</version>

    <properties> <!--2-->
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
        <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
        <maven.compiler.source>17</maven.compiler.source>
        <maven.compiler.target>17</maven.compiler.target>
    </properties>
</project>
----
<1> The tuple `groupId`, `artifactId` et `version` are the coordinates which identifies one Maven project and allows referencing it from others.
<2> Optional section, here fixing the encoding and Java version to avoid conflicts later on

//-

* A *src* directory which will contains all files we want to keep in the SCM
** In *src*, there is standardly two directories: *main* et *test* which respectively contain production code, and test code (code not included in binaries produced during the *_packaging_* phase)
*** In each of these two directories, a directory named after the language used exists, in this exemple: *java*, but can be *groovy*, *kotlin*, etc.
**** Finally, in these directories, we put the code. This code is organized in packages, being themselves composed of directories

.Structure of a Maven project
image::maven_structure.png[align=center]

==== Lifecycle of a Maven project

By default, Maven uses a lifecycle which allows a majority of projects to be built with minimal configuration.

The main *phases* are:

* *clean* : delete all created / generated files
* *compile* : compile _main_ sources
* *test-compile* : compile _test_ sources
* *test* : run tests
* *package* : create the binary archive (*jar* by default)
* *install* : copy the binary archive in the local Maven repository
* *deploy* : copy the binary archive in a distant Maven repository
* *site* : generate the documentation

Each phase can be associated to one or more *plugins*, which makes Maven very extensive.

The default associations are:

image::maven_circle.png[align=center]

Some plugins are supplied by the Maven team, as the *maven-clean-plugin*, which deletes all generated files.

Others are created by the community, and do not require evolution in Maven itself. For example:

* *cukedoctor-maven-plugin* : create an HTML report of Cucumber tests execution
* *checkstyle-maven-plugin* : statically analyze the code, and fail the build in case of a rule violation

Source : https://maven.apache.org/guides/introduction/introduction-to-the-lifecycle.html

==== Configuration tags
All tags must be contained in the `<project>` bloc.

Among the most used tags, there is:

* `properties`: this tag contains key-value pairs, which can be used later on, either by convention by plugins, or explicitly using a language expression `${my-property}`

[source,xml]
----
<properties>
    <my-test-lib.version>1.2</my-test-lib.version>
</properties>
----

* `dependencies`: this tag contains all dependencies used tin the project. A dependency can be a sibling module or and external library available from a remote repository.

[source,xml]
----
<dependencies>
    <dependency> <!--1-->
        <groupId>com.mycompany</groupId>
        <artifactId>my-lib</artifactId>
        <version>1.45.3</version>
    </dependency>
    <dependency>
        <groupId>com.mycompany</groupId>
        <artifactId>my-test-lib</artifactId>
        <version>${my-test-lib.version}</version> <!--2-->
        <scope>test</scope> <!--3-->
    </dependency>
</dependencies>
----
<1> The `dependencies` bloc is composed of `dependency` (singular) blocs, each containing the coordinates of one dependency
<2> The version value references the `my-test-lib.version` property, therefore `1.2`
<3> This second dependency has the `test` *_scope_*, hence this dependency is only available for test code

//-

* `build/plugins`: this tag contains all plugins used by the project as well as their configurations

[source,xml]
----
<build>
    <plugins>
        <plugin> <!--1-->
            <groupId>org.apache.maven.plugins</groupId> <!--2-->
            <artifactId>maven-surefire-plugin</artifactId>
            <version>2.22.2</version>
            <configuration> <!--3-->
                <failIfNoTests>true</failIfNoTests>
            </configuration>
        </plugin>
    </plugins>
</build>
----
<1> As for the `dependencies` tag, the `plugins` one contains `plugin` (singular) blocs
<2> Here the `maven-surefire-plugin` plugin is used. It is the default plugin for executing tests. By adding this bloc, the version is fixed and the configuration overridden. A plugin is a Maven project, and as such, has coordinates like dependencies
<3> The `configuration` tag allows to change the default behavior of the plugin. Here the project build will fail if no test is found

//-

* `profiles`: this tag allow to add configuration fragments that can be activated/ deactivated at will, without changing the project. A profile may add `properties`, `dependencies`, `plugins` and even `modules` (used in multi-modules project)

[source,xml]
----
<profiles>
    <profile>
        <id>disable-tests</id> <!--1-->
        <properties>
            <maven.test.skip>true</maven.test.skip>
        </properties>
    </profile>
</profiles>
----
<1> Mandatory tag, a profile must have an ID, used to activate it from the command line. For example: `mvn install -P disable-tests`

=== JUnit

Java does not supply a built-in tool or API to describe or run tests.

Maven supply a dedicated directory, phases (compilation & execution), and a scope to handle this code which is not going into production.
However, Maven does not supply either tool or API to describe and execute these tests.

This is where _test frameworks_ come in.
There are several of them, and JUnit is the most used today in the Java world.

==== Utilisation of JUnit-Jupiter API

[source,java]
----
class CalculatorTest {

    private final Calculator calculator = new Calculator();

    @Test // <1>
    void simple_division() {
        int result = calculator.divide(8).by(2); // <2>

        Assertions.assertThat(result) // <3>
            .as("division of 8 by 2")
            .isEqualTo(4); // <4>
    }
    
    @Test
    void division_by_zero_should_throw() {
        Assertions.assertThatExceptionOfType(IllegalArgumentException.class) // <5>
            .isThrownBy(() -> calculator.divide(3).by(0)) // <6>
            .withMessage("Cannot divide by zero"); // <7>
    }
    
    @ParameterizedTest // <8>
    @CsvSource({
        "0, 3, 3",
        "3, 4, 7"
    }) // <9>
    void addition_cases(int a, int b, int expectedResult) { // <10>
        int result = calculator.add(a).and(b);
        
        Assertions.assertThat(result) // <3>
            .as("addition of " + a + " and " + b)
            .isEqualTo(expectedResult);
    }
}
----
<1> Method mark as a test one, because annotated with `org.junit.jupiter.api.Test`
<2> Trigger event, some _main_ code is executed
<3> The result of the main code call is checked (here with the *AssertJ* library)
<4> These three lines compose a single expression, as the compiler ignores line breaks. This kind of writing is called *fluent interface* and is built on consecutive method calls in such as way that they compose a meaningful sentence. Here, literally: check that the `result` variable as the "division of 8 by 2" is equal to 4
<5> Check that an error is produced. This test will break if no error is produced or if the type of the error is different from the one expected
<6> A function is given to the assertion API, it will be executed by the library, in a `try / catch` bloc
<7> Check of the error message, if the message does not match the expected one, the test will fail
<8> Method marked as a parameterized test, it will be executed as many times as there are test cases. In this example, the method will be executed twice
<9> The dataset, here supplied as inlined CSV (Comma Separated Values), other sources may be used
<10> Method parameters must match those in a test case, and follow the same order.

==== How JUnit works with Maven

*JUnit-Jupiter* is composed of several parts:

* An API to describe test methods (`@Test`, etc.)
* An execution engine which is able to detect and run test methods

JUnit also supplies a launcher of execution engine: *junit-platform-launcher*

Finally, the *maven-surefire-plugin* plugin "knows" how to connect (among other tools) to this  _launcher_ (since version 2.22.0).

[NOTE]
====
To summarize :

* The *test* phase of Maven is associated to the *maven-surefire-plugin* plugin
* This plugin can run *junit-platform-launcher* (if this library is available in the _classpath_)
* This _launcher_ can run execution engines built with the *junit-platform-engine* API, *JUnit-Jupiter* being one of them
* *JUnit-Jupiter* can detect and run tests described with its API
====

==== A story about JUnit

JUnit is an old framework (1997) and has evolved a lot through Java versions.
The version 4, released in 2006 (after Java 1.5), has been broadly adopted and used during a long time, due to its simplicity using annotations (`@Test`).
In 2015, a crowdfunding campaign is launched to create JUnit5, a complete rewriting of the framework.

Right from the start, the team choose to create modular and dedicated APIs to avoid the same slides in the previous API, which was both very permissive and very complicated.

This was due to the initial API being designed to mark test methods, but evolved to allow plugins to describe tests arbitrarily (Cucumber, etc.) where a test can be a paragraph in a text file.

Furthermore, even if there was several extension points in version 4, the most used was `Runner`, which could not be composed.
This lead plugin teams to supply tools available from several extension points (`Runner`, `Rule`, initialization in `setUp` method, etc.) to bypass this flaw.

JUnit5 team stated that each paradigm should have its own API and execution engine, so that the code can be more specific, and much simple.

The resulting architecture is:

image::junit5_architecture.png[align=center]

*JUnit-platform* is a framework to build and run execution engines.

*JUnit-Vintage* is an execution engine compatible with JUnit4 API.

*JUnit-Jupiter* is an execution engine with a new API which offers multiple and composable extension points.
