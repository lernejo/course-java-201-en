== Techniques & bonnes pratiques
:hardbreaks-option:

=== KISS, YAGNI & DRY

Quelques principes populaires qui circulent dans les communautés de développeurs :

* **K**eep **I**t **S**tupid **S**imple : Le plus simple, le mieux.
Faire simple n’est cependant pas toujours facile.
* **Y**ou **A**in’t **G**onna **N**eed **I**t : N’ajouter que du code utile dans le présent.
Les prédictions sur le futur peuvent se révéler fausses et la conception qui a été faites "en prévision de" peut faire obstacle une fois le futur devenu présent.
* **D**on’t **R**epeat **Y**ourself : La duplication est mal vue parmi les développeurs, et amène plusieurs problèmes :
** C’est plus de travail, il faut écrire, tester et maintenir plusieurs fois le même code
** En cas de bug, il faut corriger à de multiples endroits, certains pouvant être oubliés

C’est cette même simplicité que l’on retrouve dans deux des douze principes du *Manifeste Agile* :

* Our highest priority is to satisfy the customer through early and continuous delivery of [.underline]#*valuable*# software
* Simplicity [the art of maximizing the amount of work not done] is essential.

=== Logs

.Exemple de log peu utile
[source]
----
2017-02-04 22:33:12 [thread-1] com.github.some.project.DatabaseService l.74 #################
2017-02-04 22:33:12 [thread-2] com.github.some.project.DatabaseService l.75 START
2017-02-04 22:33:12 [thread-1] com.github.some.project.DatabaseService l.93 STOP in 17ms
2017-02-04 22:33:12 [thread-2] com.github.some.project.DatabaseService l.94 #################
2017-02-04 22:33:12 [thread-1] com.github.some.project.DatabaseService l.124 java.sql.SQLIntegrityConstraintViolationException
at org.h2.message.DbException.getJdbcSQLException(DbException.java:345)
at org.h2.message.DbException.get(DbException.java:179)
at org.h2.message.DbException.get(DbException.java:155)
at org.h2.command.CommandContainer.update(CommandContainer.java:98)
at org.h2.command.Command.executeUpdate(Command.java:258)
at org.h2.jdbc.JdbcPreparedStatement.execute(JdbcPreparedStatement.java:201)
... 50 more
----

.C’est déjà mieux
[source]
----
2017-02-04 22:33:12.332 INFO  5jhgd45ui74h c.g.s.p.UserService.create [Joshua] [Bloch] Save successful
2017-02-04 22:33:12.758 INFO  6jyg45hgduyg c.g.s.p.UserService.create [Doug] [Lea] Save successful
2017-02-04 22:33:12.964 ERROR hg457gehe4rt c.g.s.p.UserService.create [James] [Gosling] Save KO: already exists
----

Les logs ou fichiers d’évènements sont ces _fichiers_ qui contiennent les informations nécessaires au diagnostique en cas de problème.
Elles peuvent également être utilisées comme source de données pour créer des métriques de supervision.
Les logs sont souvent la seule trace de la chronologie des évènements et sont d’autant plus importantes dans les applications à fort traffic, où résoudre le problème d’un utilisateur peut s’apparenter à chercher une aiguille dans une botte de foin.

Afin de pouvoir exploiter au mieux les logs, il est important de les centraliser.
C’est-à-dire les envoyer dans un même endroit, que ce soit dans un :

* Système de fichier, sur lequel on pourra utiliser la commande `grep` par exemple
* _ElasticSearch_, _Loki_ ou équivalent, sur lequel on pourra faire des requêtes
* SAAS dont c’est le coeur de métier (_Datadog_, _Logz.io_, etc.)

Les logs doivent être claires et apporter le maximum d’information possible.
Pour cela on évite les logs visuelles ou de _debug_.

==== La stack Elastic

Il existe plusieurs solutions de centralisation _on premise_, la plus connue étant la suite proposée par _Elastic_ : *ELK* (**E**lasticSearch, **L**ogstash, **K**ibana).
Aujourd’hui un peu datée, des composants peuvent être remplacés, la chaîne peut être plus complexe pour mieux gérer le dimensionnement, mais la structure reste néanmoins identique.

image::elk_stack.png[align=center]

La brique *Logstash* permet de découper les lignes de logs en documents structurés (JSON) pour ensuite les envoyer à *ElasticSearch*.
*ElasticSearch* indexe les documents reçus et propose une API de recherche utilisée par *Kibana*.
*Kibana* fourni une interface Web qui satisfait aussi bien à la recherche exploratoire qu’à la création de tableaux de bord pour suivre l’état du système.

==== Bibliothèques de log

Côté applicatif, il existe de nombreuses bibliothèques pour écrire dans des fichiers de logs.

Rien que dans l’univers Java, on peut trouver

* JUL (**J**ava **U**til **L**ogging) minimaliste, fourni par le JDK
* Apache JULI (**J**ava **U**til **L**ogging **I**nterface)
* Apache Commons Logging
* Apache Log4J
* JBoss Logging
* Logback
* etc.

On retrouve dans ces différents outils des concepts communs :

* Découplage entre le composant qui collecte les logs (`Logger`) et celui qui écrit à l’extérieur du système (`Appender`)
* Configuration extérieure au code (fichier, propriétés système)
* Niveaux de sévérités
** *DEBUG* : utilise pour le développement, invisible une fois l’application déployée en dehors d’un poste de développement
** *INFO* : information sur un évènement dans le système (changement d’état ou réaction à une sollicitation exogène)
** *WARN* : une erreur est survenue, le système ne s’est pas comporté comme prévu, mais aucune intervention humaine n’est requise immédiatement
** *ERROR* : une erreur est survenue, une intervention humaine est requise pour corriger le problème
** (*FATAL* : une erreur [.underline]#irrémédiable# est survenue, suite à quoi le système s’est arrêté)

[NOTE]
====
Une erreur métier n’est pas forcément une erreur technique.
Par exemple : un utilisateur qui entre un mauvais mot de passe est un cas métier normal, géré par le code, et l’évènement correspondant (s’il est tracé) est de sévérité *INFO*.
====

===== Architecture de SLF4J

Le problème avec cette multiplicité de choix d’outil est que l’écosystème s’est construit de manière hétérogène.

* Tomcat utilise *JUL* à travers l’abstraction *JULI*.
* Spring utilise *Apache Commons Logging*.
* Le client *HBase* officiel utilise *Log4j*.
* Etc.

Une application qui utilise différents frameworks et bibliothèques devrait alors configurer chacune de ces technologies de _logging_ et ce de manière cohérente (même format de ligne, même fichier, même sévérité minimum, etc.).

Ce serait pénible, et le risque de problèmes serait élevé (concurrence d’accès sur un même fichier, etc.).

Une technologie existe cependant, pour unifier tous ces outils : *SLF4J*.

Cet outil est composé

* D’une *_API abstraite_* représentant de manière unifiée un grand nombre des fonctionnalités des bibliothèques de log existantes
* D’*_adaptateurs_* entre cette API et les bibliothèques de logs existantes qui ne l’implémentent pas
* De *_bridges_*, bibliothèques ayant la même compatibilité binaire (même noms qualifiés des classes, même signatures des méthodes) que les bibliothèques de logs existantes, mais redirigeant les messages vers l’*_API abstraite_*

image::slf4j_bridges.png[align=center]

Dans une application mettant cette technologie à profit, toutes les logs sont redirigées vers cette *_API abstraite_* et envoyées vers une seule et unique bibliothèque de log.

La configuration est alors faite une fois, et il n’y a plus de risque de concurrence d’accès.

===== MDC (Mapped Diagnostic Context)

Le *MDC* est un outil fourni par la plupart des bibliothèques de log qui permet de transporter de l’information dans un même thread.

L’idée est d’enrichir les informations transverses utiles pour une ligne de log au fur et à mesure de leur disponibilité, sans avoir à les passer en paramètres de toutes les méthodes précédant l’écriture du message.

Considérant ce code :

.Fichier MyController.java
[source,java]
----
class MyController {

    private final MyService service;

    public User newUser(User user, @Header("correlationId") String correlationId) {
        return service.newUser(user, correlationId);
    }
}
----

.Fichier MyService.java
[source,java]
----
class MyService {

    private final Logger logger = LoggerFactory.getLogger(MyService.class);
    private final MyRepository repository;

    public User newUser(User user, String correlationId) {
        if(isValid(user, correlationId)) {
            return repository.save(user, correlationId);
        } else {
            throw new InvalidUserException();
        }
    }
    
    private boolean isValid(User user, String correlationId) {
        if(user.age > 110) {
            logger.info("[" + correlationId + "] Invalid User: too old");
            return false;
        } else if(user.age < 1) {
            logger.info("[" + correlationId + "] Invalid User: too young");
            return false;
        }
        return true;
    }
}
----

La variable `correlationId` est passé systématiquement car il est nécessaire de la logger à chaque fois pour réconcilier plusieurs lignes de logs qui concernent le même appel d’un utilisateur.

C’est une bonne candidate pour le *MDC* :

.Fichier MyController.java
[source,java]
----
class MyController {

    private final MyService service;

    public User newUser(User user, @Header("correlationId") String correlationId) {
        MDC.put("correlationId", correlationId);
        return service.newUser(user);
    }
}
----

.Fichier MyService.java
[source,java]
----
class MyService {

    private final Logger logger = LoggerFactory.getLogger(MyService.class);
    private final MyRepository repository;

    public User newUser(User user) {
        if(isValid(user)) {
            return repository.save(user);
        } else {
            throw new InvalidUserException();
        }
    }

    private boolean isValid(User user) {
        if(user.age > 110) {
            logger.info("Invalid User: too old");
            return false;
        } else if(user.age < 1) {
            logger.info("Invalid User: too young");
            return false;
        }
        return true;
    }
}
----

Il n’y a plus qu’à configurer le bon format de sortie des lignes de log pour que le `correlationId` soit présent.

.Fichier logback.xml
[source,xml]
----
<configuration>

  <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
    <encoder>
      <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - [%X{correlationId}] %msg%n</pattern> <!--1-->
    </encoder>
  </appender>

  <root level="DEBUG">
    <appender-ref ref="STDOUT" />
  </root>
</configuration>
----
<1> Ici une ligne de log sera structurée comme suit : <heure> <nom du thread> <sévérité> <nom de la classe> - <correlationId> <message>

==== Logs GC

Les logs applicatives sont une chose, mais quand un problème arrive en production, son origine ou ses symptômes peuvent être techniques.

Il est important de ne pas oublier d’activer les logs du **G**arbarge **C**ollector.
Cela se fait avec un flag sur la ligne de commande du démarrage de la JVM :

`-Xlog:gc=debug:file=gc.log:pid,time,uptimemillis:filecount=5,filesize=1M`

Ici la JVM va écrire les évènements à partir de la sévérité *debug* dans un fichier *gc.log* (en gérant la rotation sur 5 fichiers max de 1M chacun) avec les informations PID (processus ID), heure et durée d’exécution de l’application.

Plus d’options ici : https://openjdk.java.net/jeps/158

[.underline]#Alternativement# des outils de collecte de métriques tels que *Micrometer* peuvent exporter ces informations vers des systèmes ingérant des _séries temporelles_ (Time Series) tels que *Graphite*, *Warp10* ou *Prometheus* (pour du on-premise).

==== Heap Dump
Quand la JVM s’arrête de manière non prévue, cela peut être à cause d’un problème de mémoire (**O**ut **O**f **M**emory error) et dans ce cas l’investigation peut se faire sur la base d’un *Heap Dump*.

Un *Heap Dump* est une projection sur fichier de l’état de la mémoire de la JVM.

Voici donc le flag à ne pas oublier sur la ligne de commande du démarrage de la JVM :

`-XX:+HeapDumpOnOutOfMemoryError`

Par la suite un tel fichier peut être analysé avec des outils comme *Eclipse MAT* (gratuit) ou *JProfiler* (payant).

=== Supervision

La collecte de logs et de métriques forme la base de la _supervision_ d’un système.

Sur cette base, il est nécessaire d’ajouter des composants pour transformer ces données brutes en :

* Alertes, dans le cas où un comportement anormal est détecté
* Tableaux de bord, pour investiguer un comportement anormal, trouver des correlations et converger vers l’origine du problème.

La supervision, c’est l’outillage qui permet de suivre l’état d’un système, de comprendre son fonctionnement, et même de prévoir son utilisation.

[TIP]
====
Il faut néanmoins faire preuve de retenue et ne garder que les informations qui ont de la valeur, au risque de se perdre dans trop d’information et de devoir stocker d’énormes quantités d’informations inutiles.

Le résultat doit être construit à l’aide de ces trois questions :

* Quels sont les comportements du système que l’on souhaite identifier comme problématiques (service indisponible, utilisation anormale, etc.) ?
* Quels comportements du système souhaite-t-on comprendre (coup de bélier, interruption de services externes, etc.) ?
* Où placer les sondes qui remonterons les informations nécessaires ?
====

Que ce soit des outils d’indexation de document, de stockage de séries temporelles ou des bases de données, tous sont des sources d’information pour la constitution de tableaux de bord et d’alerte.

L’outil open-source le plus complet aujourd’hui pour aggréger ces sources est Grafana

image::grafana.png[align=center]

